<!DOCTYPE html>
<html lang="en">
<head>

    <meta charset="utf-8">
    <title>Home - Documentation</title>


    <script src="scripts/prettify/prettify.js"></script>
    <script src="scripts/prettify/lang-css.js"></script>
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    <link href="styles/prettify.css" rel="stylesheet" type="text/css">
    <link href="styles/jsdoc.css" rel="stylesheet" type="text/css">
    <script defer src="scripts/nav.js"></script>

    <meta content="width=device-width, initial-scale=1.0" name="viewport">
</head>
<body>

<input class="nav-trigger" id="nav-trigger" type="checkbox"/>
<label class="navicon-button x" for="nav-trigger">
    <div class="navicon"></div>
</label>

<label class="overlay" for="nav-trigger"></label>

<nav>


    <h2><a href="index.html">Home</a></h2>
    <h3>Classes</h3>
    <ul>
        <li><a href="Action.html">Action</a></li>
        <li><a href="global.html#Gesture">Gesture</a></li>
        <li><a href="gestureRecognizer.html">gestureRecognizer</a></li>
        <li><a href="module-facialRecognition.faceLandmarker.html">faceLandmarker</a></li>
    </ul>
    <h3>Interfaces</h3>
    <ul>
        <li><a href="ActionAttributes.html">ActionAttributes</a></li>
        <li><a href="ActionCreationAttributes.html">ActionCreationAttributes</a></li>
        <li><a href="GestureAttributes.html">GestureAttributes</a></li>
        <li><a href="GestureCreationAttributes.html">GestureCreationAttributes</a></li>
        <li><a href="ToolbarItemType.html">ToolbarItemType</a></li>
    </ul>
    <h3>Global</h3>
    <ul>
        <li><a href="global.html#Home">Home</a></li>
        <li><a href="global.html#MinimalView">MinimalView</a></li>
        <li><a href="global.html#NavBar">NavBar</a></li>
        <li><a href="global.html#SourceItem">SourceItem</a></li>
        <li><a href="global.html#TopAppBar">TopAppBar</a></li>
        <li><a href="global.html#Webcam">Webcam</a></li>
        <li><a href="global.html#createAction">createAction</a></li>
        <li><a href="global.html#createGesture">createGesture</a></li>
        <li><a href="global.html#deleteAction">deleteAction</a></li>
        <li><a href="global.html#deleteGesture">deleteGesture</a></li>
        <li><a href="global.html#formatTime">formatTime</a></li>
        <li><a href="global.html#getAction">getAction</a></li>
        <li><a href="global.html#getAllActions">getAllActions</a></li>
        <li><a href="global.html#getAllGestures">getAllGestures</a></li>
        <li><a href="global.html#getGesture">getGesture</a></li>
        <li><a href="global.html#isBuild">isBuild</a></li>
        <li><a href="global.html#locDb">locDb</a></li>
        <li><a href="global.html#openWebpage">openWebpage</a></li>
        <li><a href="global.html#pressKey">pressKey</a></li>
        <li><a href="global.html#releaseKey">releaseKey</a></li>
        <li><a href="global.html#updateAction">updateAction</a></li>
        <li><a href="global.html#updateGesture">updateGesture</a></li>
    </ul>

</nav>

<div id="main">


    <section class="package">
        <h3></h3>
    </section>


    <section class="readme usertext">
        <article>
            <div>
                <img alt="logo"
                     src="https://raw.githubusercontent.com/JumppanenTomi/presentation-tool-with-hand-gestures/master/src/assets/handwave-logo.svg" width="300"/>
                <div>
                    Harness the power of your hand gestures to effortlessly control your computer with Handwave, an
                    AI-based application that utilizes Google MediaPipe for gesture recognition and face landmarking.
                    <h2>Overview</h2>
                    <p>Handwave transforms your hand movements into intuitive commands, enabling you to navigate your
                        computer, control presentations, and interact with applications without the need for traditional
                        input devices. Leveraging MediaPipe's robust hand and face recognition capabilities, Handwave
                        integrates gesture recognition with mouse control, presentation recording, and facial detection,
                        making it a versatile tool for enhancing accessibility and productivity.</p>
                    <h2>Technology Stack</h2>
                    <ul>
                        <li><strong>Front-end</strong>: React, TypeScript, Vite, Google Mediapipe</li>
                        <li><strong>Back-end</strong>: Electron, Sequelize, SQLite3, nut-js</li>
                    </ul>
                    <h2>Modal Dataset</h2>
                    <p>Handwave utilizes HaGRID Dataset, a valuable resource for developing hand gesture recognition
                        systems. It contains a variety of gestures, including common symbols, numbers, and commands, as
                        well as a wide range of subjects and lighting conditions. Key enhancements to the dataset
                        include:</p>
                    <ul>
                        <li>An expansion to 18 gestures</li>
                        <li>An augmentation to 18,000 images</li>
                        <li>Achieving a test accuracy of 0.86</li>
                    </ul>
                    <div>
                        <img alt="gestures"
                             src="https://raw.githubusercontent.com/JumppanenTomi/presentation-tool-with-hand-gestures/master/src/assets/gestures.jpg"/>
                        <div>
                            <h2>Features</h2>
                            <h3>Gesture Recognition:</h3>
                            <ul>
                                <li>Seamlessly recognize hand gestures using MediaPipe Hands</li>
                                <li>Map gestures to custom-defined actions for intuitive input</li>
                                <li>Receive visual feedback for gesture recognition</li>
                            </ul>
                            <h3>Hand Landmarking:</h3>
                            <ul>
                                <li>Control the mouse pointer using the &quot;L&quot; gesture (&quot;three&quot; 2 in
                                    HaGRID dataset)
                                </li>
                                <li>Perform left-click selections using thumbs</li>
                            </ul>
                            <h3>Map gestures to HID events</h3>
                            <ul>
                                <li>Use macro maker to map gestures to keyboard keys or or key combinations</li>
                                <li>Control, click and drag mouse with gestures</li>
                            </ul>
                            <h3>Face Landmarking:</h3>
                            <ul>
                                <li>Track facial landmarks using MediaPipe Face Mesh</li>
                                <li>Prevent unintentional keystrokes by maintaining face detection</li>
                            </ul>
                            <h3>Presentation Recording.</h3>
                            <ul>
                                <li>Select window or applications for interacting and recording</li>
                                <li>Save recordings to your local drive once finished</li>
                            </ul>
                            <h3>Cross-platform Compatibility:</h3>
                            <ul>
                                <li>Electron enables deployment on various operating systems (Windows, macOS, Linux)
                                </li>
                            </ul>
                            <h2>Authors</h2>
                            <ul>
                                <li>Tomi Jumppanen</li>
                                <li>Roope Laine</li>
                                <li>Anton Tugushi</li>
                                <li>Dat Pham</li>
                            </ul>
                            <h2>Credits</h2>
                            <ul>
                                <li><a href="https://github.com/hukenovs/hagrid">HaGRID</a></li>
                                <li><a href="https://nut-tree.github.io/apidoc/">nut-js</a></li>
                                <li>
                                    <a href="https://github.com/electron-vite/electron-vite-react">electron-vite-react</a>
                                </li>
                            </ul>
        </article>
    </section>


</div>

<br class="clear">

<footer>
    Documentation generated by <a href="https://github.com/jsdoc3/jsdoc">JSDoc 4.0.2</a> on Sun Dec 10 2023 18:08:58
    GMT+0200 (It√§-Euroopan normaaliaika) using the <a href="https://github.com/clenemt/docdash">docdash</a> theme.
</footer>

<script>prettyPrint();</script>
<script src="scripts/polyfill.js"></script>
<script src="scripts/linenumber.js"></script>


</body>
</html>